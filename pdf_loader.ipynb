{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5b6a93b",
   "metadata": {},
   "source": [
    "RAG Pipeline-Data Ingestion to Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dd217c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\RAG\\rag_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 0}, page_content='Civil Supplies Project Documentation \\nThe Civil Supplies Project automates the monitoring and management of warehouse activities using \\nthree integrated systems: \\n- Facial Recognition System for identifying individuals. \\n- Gunny Bags Counting System for tracking loading and unloading activities. \\n- Number Plate Recognition System for vehicle access control. \\nThese systems work together through a unified pipeline that processes live video feeds, enhancing \\noperational efficiency, security. \\n \\nPrerequisites & Configuration \\nBefore running the Civil Supplies Warehouse pipeline, ensure these secrets are configured in GitHub: \\n Azure Configuration \\n• \\nAZURE_TENANT_ID – Tenant ID for Azure authentication. \\n• \\nAZURE_CLIENT_ID – Client ID of the registered Azure application. \\n• \\nAZURE_CLIENT_SECRET – Client secret for the registered Azure application. \\n• \\nAZURE_STORAGE_ACCOUNT_NAME – Storage account name. \\n• \\nAZURE_CONTAINER_NAME – Container name for storing CCTV video chunks. \\nPostgreSQL Database \\n• \\nPG_HOST – Host IP/hostname of the database server. \\n• \\nPG_PORT – Database port. \\n• \\nPG_USER – Database user. \\n• \\nPG_PASSWORD – Database user password. \\n• \\nPG_DATABASE – Database name. \\n \\nPipeline Breakdown: \\n1. Video Ingestion and Storage \\n• \\nComponent: AWS Lambda (WarehouseAzure-S3-Transfer-Video-Function)'),\n",
       " Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 1}, page_content='• \\nProcess: Continuously monitors the live CCTV feed (RTSP/RTMP). \\n• \\nAction: Segments the feed into short video clips (.ts/.mp4) and uploads them to Azure Blob \\nStorage (e.g., spectradevdev). \\n \\n2. Job Triggering \\n• \\nComponent: AWS Lambda (API Trigger) \\n• \\nProcess: Listens for new blob upload events in Azure. \\n• \\nAction: Sends an HTTP POST request (/api/process) to the FastAPI Main Service, including \\nthe blob URL and task metadata. \\n \\n3. Frame Preparation \\n• \\nComponent: FastAPI Main Service \\n• \\nSubmodules: \\no \\nazure_downloader.py → Downloads the video clip from Azure Blob. \\no \\nframe_extractor.py → Converts the video into sequential frames for analysis. \\n \\n4. Orchestration and Model Inference \\n• \\nComponent: Task Orchestrator (videoprocessor.py) \\n• \\nProcess: Reads task type (Gunny bag, Face, NumberPlate) from the trigger payload. \\n• \\nAction: Dispatches frames to the relevant services: \\no \\nGunnybag Counting Service \\no \\nFacial Recognition Service \\no \\nLicense Plate Recognition Service \\n• \\nOutput: Each service processes frames and produces structured results. \\n \\n5. Persistence and Response \\n• \\nComponent: DB Handler + FastAPI Response'),\n",
       " Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 2}, page_content='• \\nProcess: \\no \\nDB Handler writes structured results into corresponding database tables (gunny \\nbags, faces, numberplates). \\no \\nFastAPI endpoint sends a JSON response back to the client confirming job \\ncompletion. \\nSystem Architecture:'),\n",
       " Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 3}, page_content='Services  \\n1. Facial Recognition System \\nThe Facial Recognition System identifies individuals captured in warehouse CCTV feeds. It aims to \\nautomate identity verification, improve security, and maintain accurate logs. \\n1.1 Workflow \\nFrame Input  \\n      ↓ \\nPerson Detection (YOLOv8l) \\n      ↓ \\nTracking (BoT-SORT) \\n      ↓ \\nFace Cropping \\n      ↓ \\nFace Recognition (Buffalo_L) \\n      ↓ \\nResult Aggregation \\n      ↓ \\nFinal Output \\n \\n1.2 Models Used \\n• \\nYOLOv8l \\no \\nTask: Person detection in frames. \\no \\nmAP (mean Average Precision): 52.9. \\n• \\nBuffalo_L (InsightFace) \\no \\nTask: Face embedding extraction for recognition. \\no \\nAccuracy: 93.16% on standard benchmarks.'),\n",
       " Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 4}, page_content=\"1.3 Key Technical Components \\n- YOLOv8l: Detects persons in video frames. \\n- BoT-SORT Tracker: Maintains consistent IDs across frames. \\n- Buffalo_L Model: Extracts embeddings for recognition. \\n- FAISS: Performs fast similarity searches on embeddings. \\n- Database (face_database.pkl): Stores known embeddings. \\n- Asyncio → Offloads CPU-heavy tasks like embedding extraction and FAISS search to \\n1.4 Integration Points \\nThis module integrates with the pipeline's frame extractor and orchestrator to process faces from \\nvideo clips stored in the cloud. \\n1.5 Implementation Details \\nThe pipeline resets trackers per clip, processes every 5th frame for recognition, and aggregates \\nresults to produce consistent identity outputs. \\n2. Gunny Bags Counting System \\nThe Gunny Bags Counting System tracks and counts gunny bags being loaded or unloaded across a \\ndefined line. Its goal is to automate inventory updates and reduce manual counting errors. \\n2.1 Workflow \\n \\nInput Video \\n      ↓ \\nYOLO Detection (Gunny Bags) \\n      ↓ \\nNon-Max Suppression \\n      ↓ \\nTracking (Kalman Filter + Hungarian Algorithm) \\n      ↓ \\nCrossing Detection \\n      ↓ \\nCount Updates \\n      ↓ \\nOutput Statistics\"),\n",
       " Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 5}, page_content='2.2 Models Used  \\n• \\nYOLO (Ultralytics)  \\no \\nTask: Detect gunny bags in each video frame.  \\no \\nConfidence threshold: 0.35. \\n• \\nKalman Filter (OpenCV)  \\no \\nTask: Smooth object trajectories and predict positions when detections are \\nmissing.  \\n• \\nHungarian Algorithm (scipy.optimize.linear_sum_assignment)  \\no \\nTask: Assign detections to existing tracks with minimum cost based on IoU and \\ndistance. \\n2.3 Key Technical Components \\n- YOLO (Ultralytics): Detects gunny bags. \\n- Kalman Filter: Smooths trajectories and predicts missing detections. \\n- Hungarian Algorithm: Matches detections to tracks. \\n- Crossing Detection Logic: Determines loading/unloading events. \\n2.4 Integration Points \\nThis module integrates with the pipeline to process warehouse footage and provide real-time \\nloading/unloading statistics. \\n2.5 Implementation Details \\nTracks have defined states (tentative → confirmed). Events are detected based on line crossing, with \\nlogs produced at regular frame intervals. \\n2.6 Model Related Graphs:'),\n",
       " Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 6}, page_content='3. Number Plate Recognition System \\nThe Number Plate Recognition System identifies and verifies vehicle license plates entering or exiting \\nthe warehouse. It ensures secure access control by matching plates against an authorized database. \\n3.1 Workflow \\n \\nVideo Input \\n      ↓ \\nYOLO Detection (License Plates) \\n      ↓ \\nTracking (BoT-SORT) \\n      ↓ \\nOCR (PaddleOCR) \\n      ↓ \\nCleaning & Validation \\n      ↓ \\nFuzzy Matching with Database'),\n",
       " Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 7}, page_content='↓ \\nResult Aggregation \\n      ↓ \\nFinal Output \\n3.2 Models Used \\n• \\nYOLO (License Plate Detection):  \\no \\nTask: Detect license plates in frames.   \\no \\nmAP@0.5: 0.9759 \\no \\nAP@0.5:0.95: 0.8997 \\no \\nPrecision: 0.9849 \\no \\nRecall: 0.9457 \\n• \\nPaddleOCR:  \\no \\nTask: Extract alphanumeric text from cropped license plate regions.   \\no \\nCharacter Matching Accuracy: ~96% – 98% \\no \\nBLEU Score: ~0.93% – 0.96% \\no \\nBoT-SORT Tracker: Maintain consistent tracking IDs across frames for each \\nvehicle/plate.     \\n \\n3.3 Key Technical Components \\n- YOLO: Detects license plates. \\n- PaddleOCR: Extracts alphanumeric text. \\n- BoT-SORT Tracker: Maintains persistent IDs. \\n- Regex Validators: Validate plate formats. \\n- Fuzzy Matching: Compares detected plates with database. \\n- PostgreSQL Database: Stores valid plates and access permissions. \\n3.4 Integration Points \\nThis module integrates with the pipeline orchestrator to process vehicle footage and update access \\nlogs. \\n3.5 Implementation Details \\nProcesses every nth frame (fps/3), aggregates OCR results, and locks final matches once validated \\nwith the database. \\n \\n3.6 YOLO model metric graphs:'),\n",
       " Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 8}, page_content='3.6.1. mAP over Training Epochs \\n \\n   3.6.2. Training vs Validation Loss')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader,PyMuPDFLoader\n",
    "loader=DirectoryLoader(\"data/pdf_files\", glob=\"*.pdf\",loader_cls=PyMuPDFLoader)\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f54c5f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyMuPDFLoader, PyPDFLoader\n",
    "from pathlib import Path\n",
    "# Try this first (newer LangChain versions)\n",
    "try:\n",
    "    from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "except ImportError:\n",
    "    # Fallback for older versions\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d6236ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  pdf file/s founded\n",
      "file name: Civil-Supplies-Documentation-V1.pdf\n",
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 0, 'source_file': 'Civil-Supplies-Documentation-V1.pdf', 'file_type': 'pdf'}, page_content='Civil Supplies Project Documentation \\nThe Civil Supplies Project automates the monitoring and management of warehouse activities using \\nthree integrated systems: \\n- Facial Recognition System for identifying individuals. \\n- Gunny Bags Counting System for tracking loading and unloading activities. \\n- Number Plate Recognition System for vehicle access control. \\nThese systems work together through a unified pipeline that processes live video feeds, enhancing \\noperational efficiency, security. \\n \\nPrerequisites & Configuration \\nBefore running the Civil Supplies Warehouse pipeline, ensure these secrets are configured in GitHub: \\n Azure Configuration \\n• \\nAZURE_TENANT_ID – Tenant ID for Azure authentication. \\n• \\nAZURE_CLIENT_ID – Client ID of the registered Azure application. \\n• \\nAZURE_CLIENT_SECRET – Client secret for the registered Azure application. \\n• \\nAZURE_STORAGE_ACCOUNT_NAME – Storage account name. \\n• \\nAZURE_CONTAINER_NAME – Container name for storing CCTV video chunks. \\nPostgreSQL Database \\n• \\nPG_HOST – Host IP/hostname of the database server. \\n• \\nPG_PORT – Database port. \\n• \\nPG_USER – Database user. \\n• \\nPG_PASSWORD – Database user password. \\n• \\nPG_DATABASE – Database name. \\n \\nPipeline Breakdown: \\n1. Video Ingestion and Storage \\n• \\nComponent: AWS Lambda (WarehouseAzure-S3-Transfer-Video-Function)'),\n",
       " Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 1, 'source_file': 'Civil-Supplies-Documentation-V1.pdf', 'file_type': 'pdf'}, page_content='• \\nProcess: Continuously monitors the live CCTV feed (RTSP/RTMP). \\n• \\nAction: Segments the feed into short video clips (.ts/.mp4) and uploads them to Azure Blob \\nStorage (e.g., spectradevdev). \\n \\n2. Job Triggering \\n• \\nComponent: AWS Lambda (API Trigger) \\n• \\nProcess: Listens for new blob upload events in Azure. \\n• \\nAction: Sends an HTTP POST request (/api/process) to the FastAPI Main Service, including \\nthe blob URL and task metadata. \\n \\n3. Frame Preparation \\n• \\nComponent: FastAPI Main Service \\n• \\nSubmodules: \\no \\nazure_downloader.py → Downloads the video clip from Azure Blob. \\no \\nframe_extractor.py → Converts the video into sequential frames for analysis. \\n \\n4. Orchestration and Model Inference \\n• \\nComponent: Task Orchestrator (videoprocessor.py) \\n• \\nProcess: Reads task type (Gunny bag, Face, NumberPlate) from the trigger payload. \\n• \\nAction: Dispatches frames to the relevant services: \\no \\nGunnybag Counting Service \\no \\nFacial Recognition Service \\no \\nLicense Plate Recognition Service \\n• \\nOutput: Each service processes frames and produces structured results. \\n \\n5. Persistence and Response \\n• \\nComponent: DB Handler + FastAPI Response'),\n",
       " Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 2, 'source_file': 'Civil-Supplies-Documentation-V1.pdf', 'file_type': 'pdf'}, page_content='• \\nProcess: \\no \\nDB Handler writes structured results into corresponding database tables (gunny \\nbags, faces, numberplates). \\no \\nFastAPI endpoint sends a JSON response back to the client confirming job \\ncompletion. \\nSystem Architecture:'),\n",
       " Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 3, 'source_file': 'Civil-Supplies-Documentation-V1.pdf', 'file_type': 'pdf'}, page_content='Services  \\n1. Facial Recognition System \\nThe Facial Recognition System identifies individuals captured in warehouse CCTV feeds. It aims to \\nautomate identity verification, improve security, and maintain accurate logs. \\n1.1 Workflow \\nFrame Input  \\n      ↓ \\nPerson Detection (YOLOv8l) \\n      ↓ \\nTracking (BoT-SORT) \\n      ↓ \\nFace Cropping \\n      ↓ \\nFace Recognition (Buffalo_L) \\n      ↓ \\nResult Aggregation \\n      ↓ \\nFinal Output \\n \\n1.2 Models Used \\n• \\nYOLOv8l \\no \\nTask: Person detection in frames. \\no \\nmAP (mean Average Precision): 52.9. \\n• \\nBuffalo_L (InsightFace) \\no \\nTask: Face embedding extraction for recognition. \\no \\nAccuracy: 93.16% on standard benchmarks.'),\n",
       " Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 4, 'source_file': 'Civil-Supplies-Documentation-V1.pdf', 'file_type': 'pdf'}, page_content=\"1.3 Key Technical Components \\n- YOLOv8l: Detects persons in video frames. \\n- BoT-SORT Tracker: Maintains consistent IDs across frames. \\n- Buffalo_L Model: Extracts embeddings for recognition. \\n- FAISS: Performs fast similarity searches on embeddings. \\n- Database (face_database.pkl): Stores known embeddings. \\n- Asyncio → Offloads CPU-heavy tasks like embedding extraction and FAISS search to \\n1.4 Integration Points \\nThis module integrates with the pipeline's frame extractor and orchestrator to process faces from \\nvideo clips stored in the cloud. \\n1.5 Implementation Details \\nThe pipeline resets trackers per clip, processes every 5th frame for recognition, and aggregates \\nresults to produce consistent identity outputs. \\n2. Gunny Bags Counting System \\nThe Gunny Bags Counting System tracks and counts gunny bags being loaded or unloaded across a \\ndefined line. Its goal is to automate inventory updates and reduce manual counting errors. \\n2.1 Workflow \\n \\nInput Video \\n      ↓ \\nYOLO Detection (Gunny Bags) \\n      ↓ \\nNon-Max Suppression \\n      ↓ \\nTracking (Kalman Filter + Hungarian Algorithm) \\n      ↓ \\nCrossing Detection \\n      ↓ \\nCount Updates \\n      ↓ \\nOutput Statistics\"),\n",
       " Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 5, 'source_file': 'Civil-Supplies-Documentation-V1.pdf', 'file_type': 'pdf'}, page_content='2.2 Models Used  \\n• \\nYOLO (Ultralytics)  \\no \\nTask: Detect gunny bags in each video frame.  \\no \\nConfidence threshold: 0.35. \\n• \\nKalman Filter (OpenCV)  \\no \\nTask: Smooth object trajectories and predict positions when detections are \\nmissing.  \\n• \\nHungarian Algorithm (scipy.optimize.linear_sum_assignment)  \\no \\nTask: Assign detections to existing tracks with minimum cost based on IoU and \\ndistance. \\n2.3 Key Technical Components \\n- YOLO (Ultralytics): Detects gunny bags. \\n- Kalman Filter: Smooths trajectories and predicts missing detections. \\n- Hungarian Algorithm: Matches detections to tracks. \\n- Crossing Detection Logic: Determines loading/unloading events. \\n2.4 Integration Points \\nThis module integrates with the pipeline to process warehouse footage and provide real-time \\nloading/unloading statistics. \\n2.5 Implementation Details \\nTracks have defined states (tentative → confirmed). Events are detected based on line crossing, with \\nlogs produced at regular frame intervals. \\n2.6 Model Related Graphs:'),\n",
       " Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 6, 'source_file': 'Civil-Supplies-Documentation-V1.pdf', 'file_type': 'pdf'}, page_content='3. Number Plate Recognition System \\nThe Number Plate Recognition System identifies and verifies vehicle license plates entering or exiting \\nthe warehouse. It ensures secure access control by matching plates against an authorized database. \\n3.1 Workflow \\n \\nVideo Input \\n      ↓ \\nYOLO Detection (License Plates) \\n      ↓ \\nTracking (BoT-SORT) \\n      ↓ \\nOCR (PaddleOCR) \\n      ↓ \\nCleaning & Validation \\n      ↓ \\nFuzzy Matching with Database'),\n",
       " Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 7, 'source_file': 'Civil-Supplies-Documentation-V1.pdf', 'file_type': 'pdf'}, page_content='↓ \\nResult Aggregation \\n      ↓ \\nFinal Output \\n3.2 Models Used \\n• \\nYOLO (License Plate Detection):  \\no \\nTask: Detect license plates in frames.   \\no \\nmAP@0.5: 0.9759 \\no \\nAP@0.5:0.95: 0.8997 \\no \\nPrecision: 0.9849 \\no \\nRecall: 0.9457 \\n• \\nPaddleOCR:  \\no \\nTask: Extract alphanumeric text from cropped license plate regions.   \\no \\nCharacter Matching Accuracy: ~96% – 98% \\no \\nBLEU Score: ~0.93% – 0.96% \\no \\nBoT-SORT Tracker: Maintain consistent tracking IDs across frames for each \\nvehicle/plate.     \\n \\n3.3 Key Technical Components \\n- YOLO: Detects license plates. \\n- PaddleOCR: Extracts alphanumeric text. \\n- BoT-SORT Tracker: Maintains persistent IDs. \\n- Regex Validators: Validate plate formats. \\n- Fuzzy Matching: Compares detected plates with database. \\n- PostgreSQL Database: Stores valid plates and access permissions. \\n3.4 Integration Points \\nThis module integrates with the pipeline orchestrator to process vehicle footage and update access \\nlogs. \\n3.5 Implementation Details \\nProcesses every nth frame (fps/3), aggregates OCR results, and locks final matches once validated \\nwith the database. \\n \\n3.6 YOLO model metric graphs:'),\n",
       " Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 8, 'source_file': 'Civil-Supplies-Documentation-V1.pdf', 'file_type': 'pdf'}, page_content='3.6.1. mAP over Training Epochs \\n \\n   3.6.2. Training vs Validation Loss')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_pdf_files(pdf_dir):\n",
    "    all_documents=[]\n",
    "    pdf_dir=Path(pdf_dir)\n",
    "    pdf_files=list(pdf_dir.glob(\"*.pdf\"))\n",
    "    print(len(pdf_files), \" pdf file/s founded\")\n",
    "    for file in pdf_files:\n",
    "        print(\"file name:\",file.name)\n",
    "        loader=PyMuPDFLoader(str(file))\n",
    "        documents=loader.load()\n",
    "        for doc in documents:\n",
    "            doc.metadata['source_file']=file.name\n",
    "            doc.metadata['file_type']=\"pdf\"\n",
    "        all_documents.extend(documents)\n",
    "        print(len(all_documents))\n",
    "    return all_documents\n",
    "all_pdf_documents=read_pdf_files(\"data/pdf_files\")\n",
    "all_pdf_documents\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cc267a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitted 9 into 14 chunks\n",
      "[Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 0, 'source_file': 'Civil-Supplies-Documentation-V1.pdf', 'file_type': 'pdf'}, page_content='Civil Supplies Project Documentation \\nThe Civil Supplies Project automates the monitoring and management of warehouse activities using \\nthree integrated systems: \\n- Facial Recognition System for identifying individuals. \\n- Gunny Bags Counting System for tracking loading and unloading activities. \\n- Number Plate Recognition System for vehicle access control. \\nThese systems work together through a unified pipeline that processes live video feeds, enhancing \\noperational efficiency, security. \\n \\nPrerequisites & Configuration \\nBefore running the Civil Supplies Warehouse pipeline, ensure these secrets are configured in GitHub: \\n Azure Configuration \\n• \\nAZURE_TENANT_ID – Tenant ID for Azure authentication. \\n• \\nAZURE_CLIENT_ID – Client ID of the registered Azure application. \\n• \\nAZURE_CLIENT_SECRET – Client secret for the registered Azure application. \\n• \\nAZURE_STORAGE_ACCOUNT_NAME – Storage account name. \\n• \\nAZURE_CONTAINER_NAME – Container name for storing CCTV video chunks.'), Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 0, 'source_file': 'Civil-Supplies-Documentation-V1.pdf', 'file_type': 'pdf'}, page_content='• \\nAZURE_CONTAINER_NAME – Container name for storing CCTV video chunks. \\nPostgreSQL Database \\n• \\nPG_HOST – Host IP/hostname of the database server. \\n• \\nPG_PORT – Database port. \\n• \\nPG_USER – Database user. \\n• \\nPG_PASSWORD – Database user password. \\n• \\nPG_DATABASE – Database name. \\n \\nPipeline Breakdown: \\n1. Video Ingestion and Storage \\n• \\nComponent: AWS Lambda (WarehouseAzure-S3-Transfer-Video-Function)'), Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 1, 'source_file': 'Civil-Supplies-Documentation-V1.pdf', 'file_type': 'pdf'}, page_content='• \\nProcess: Continuously monitors the live CCTV feed (RTSP/RTMP). \\n• \\nAction: Segments the feed into short video clips (.ts/.mp4) and uploads them to Azure Blob \\nStorage (e.g., spectradevdev). \\n \\n2. Job Triggering \\n• \\nComponent: AWS Lambda (API Trigger) \\n• \\nProcess: Listens for new blob upload events in Azure. \\n• \\nAction: Sends an HTTP POST request (/api/process) to the FastAPI Main Service, including \\nthe blob URL and task metadata. \\n \\n3. Frame Preparation \\n• \\nComponent: FastAPI Main Service \\n• \\nSubmodules: \\no \\nazure_downloader.py → Downloads the video clip from Azure Blob. \\no \\nframe_extractor.py → Converts the video into sequential frames for analysis. \\n \\n4. Orchestration and Model Inference \\n• \\nComponent: Task Orchestrator (videoprocessor.py) \\n• \\nProcess: Reads task type (Gunny bag, Face, NumberPlate) from the trigger payload. \\n• \\nAction: Dispatches frames to the relevant services: \\no \\nGunnybag Counting Service \\no \\nFacial Recognition Service \\no \\nLicense Plate Recognition Service \\n•'), Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 1, 'source_file': 'Civil-Supplies-Documentation-V1.pdf', 'file_type': 'pdf'}, page_content='Gunnybag Counting Service \\no \\nFacial Recognition Service \\no \\nLicense Plate Recognition Service \\n• \\nOutput: Each service processes frames and produces structured results. \\n \\n5. Persistence and Response \\n• \\nComponent: DB Handler + FastAPI Response'), Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 2, 'source_file': 'Civil-Supplies-Documentation-V1.pdf', 'file_type': 'pdf'}, page_content='• \\nProcess: \\no \\nDB Handler writes structured results into corresponding database tables (gunny \\nbags, faces, numberplates). \\no \\nFastAPI endpoint sends a JSON response back to the client confirming job \\ncompletion. \\nSystem Architecture:'), Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 3, 'source_file': 'Civil-Supplies-Documentation-V1.pdf', 'file_type': 'pdf'}, page_content='Services  \\n1. Facial Recognition System \\nThe Facial Recognition System identifies individuals captured in warehouse CCTV feeds. It aims to \\nautomate identity verification, improve security, and maintain accurate logs. \\n1.1 Workflow \\nFrame Input  \\n      ↓ \\nPerson Detection (YOLOv8l) \\n      ↓ \\nTracking (BoT-SORT) \\n      ↓ \\nFace Cropping \\n      ↓ \\nFace Recognition (Buffalo_L) \\n      ↓ \\nResult Aggregation \\n      ↓ \\nFinal Output \\n \\n1.2 Models Used \\n• \\nYOLOv8l \\no \\nTask: Person detection in frames. \\no \\nmAP (mean Average Precision): 52.9. \\n• \\nBuffalo_L (InsightFace) \\no \\nTask: Face embedding extraction for recognition. \\no \\nAccuracy: 93.16% on standard benchmarks.'), Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 4, 'source_file': 'Civil-Supplies-Documentation-V1.pdf', 'file_type': 'pdf'}, page_content=\"1.3 Key Technical Components \\n- YOLOv8l: Detects persons in video frames. \\n- BoT-SORT Tracker: Maintains consistent IDs across frames. \\n- Buffalo_L Model: Extracts embeddings for recognition. \\n- FAISS: Performs fast similarity searches on embeddings. \\n- Database (face_database.pkl): Stores known embeddings. \\n- Asyncio → Offloads CPU-heavy tasks like embedding extraction and FAISS search to \\n1.4 Integration Points \\nThis module integrates with the pipeline's frame extractor and orchestrator to process faces from \\nvideo clips stored in the cloud. \\n1.5 Implementation Details \\nThe pipeline resets trackers per clip, processes every 5th frame for recognition, and aggregates \\nresults to produce consistent identity outputs. \\n2. Gunny Bags Counting System \\nThe Gunny Bags Counting System tracks and counts gunny bags being loaded or unloaded across a \\ndefined line. Its goal is to automate inventory updates and reduce manual counting errors. \\n2.1 Workflow \\n \\nInput Video \\n      ↓\"), Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 4, 'source_file': 'Civil-Supplies-Documentation-V1.pdf', 'file_type': 'pdf'}, page_content='2.1 Workflow \\n \\nInput Video \\n      ↓ \\nYOLO Detection (Gunny Bags) \\n      ↓ \\nNon-Max Suppression \\n      ↓ \\nTracking (Kalman Filter + Hungarian Algorithm) \\n      ↓ \\nCrossing Detection \\n      ↓ \\nCount Updates \\n      ↓ \\nOutput Statistics'), Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 5, 'source_file': 'Civil-Supplies-Documentation-V1.pdf', 'file_type': 'pdf'}, page_content='2.2 Models Used  \\n• \\nYOLO (Ultralytics)  \\no \\nTask: Detect gunny bags in each video frame.  \\no \\nConfidence threshold: 0.35. \\n• \\nKalman Filter (OpenCV)  \\no \\nTask: Smooth object trajectories and predict positions when detections are \\nmissing.  \\n• \\nHungarian Algorithm (scipy.optimize.linear_sum_assignment)  \\no \\nTask: Assign detections to existing tracks with minimum cost based on IoU and \\ndistance. \\n2.3 Key Technical Components \\n- YOLO (Ultralytics): Detects gunny bags. \\n- Kalman Filter: Smooths trajectories and predicts missing detections. \\n- Hungarian Algorithm: Matches detections to tracks. \\n- Crossing Detection Logic: Determines loading/unloading events. \\n2.4 Integration Points \\nThis module integrates with the pipeline to process warehouse footage and provide real-time \\nloading/unloading statistics. \\n2.5 Implementation Details \\nTracks have defined states (tentative → confirmed). Events are detected based on line crossing, with \\nlogs produced at regular frame intervals.'), Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 5, 'source_file': 'Civil-Supplies-Documentation-V1.pdf', 'file_type': 'pdf'}, page_content='logs produced at regular frame intervals. \\n2.6 Model Related Graphs:'), Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 6, 'source_file': 'Civil-Supplies-Documentation-V1.pdf', 'file_type': 'pdf'}, page_content='3. Number Plate Recognition System \\nThe Number Plate Recognition System identifies and verifies vehicle license plates entering or exiting \\nthe warehouse. It ensures secure access control by matching plates against an authorized database. \\n3.1 Workflow \\n \\nVideo Input \\n      ↓ \\nYOLO Detection (License Plates) \\n      ↓ \\nTracking (BoT-SORT) \\n      ↓ \\nOCR (PaddleOCR) \\n      ↓ \\nCleaning & Validation \\n      ↓ \\nFuzzy Matching with Database'), Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 7, 'source_file': 'Civil-Supplies-Documentation-V1.pdf', 'file_type': 'pdf'}, page_content='↓ \\nResult Aggregation \\n      ↓ \\nFinal Output \\n3.2 Models Used \\n• \\nYOLO (License Plate Detection):  \\no \\nTask: Detect license plates in frames.   \\no \\nmAP@0.5: 0.9759 \\no \\nAP@0.5:0.95: 0.8997 \\no \\nPrecision: 0.9849 \\no \\nRecall: 0.9457 \\n• \\nPaddleOCR:  \\no \\nTask: Extract alphanumeric text from cropped license plate regions.   \\no \\nCharacter Matching Accuracy: ~96% – 98% \\no \\nBLEU Score: ~0.93% – 0.96% \\no \\nBoT-SORT Tracker: Maintain consistent tracking IDs across frames for each \\nvehicle/plate.     \\n \\n3.3 Key Technical Components \\n- YOLO: Detects license plates. \\n- PaddleOCR: Extracts alphanumeric text. \\n- BoT-SORT Tracker: Maintains persistent IDs. \\n- Regex Validators: Validate plate formats. \\n- Fuzzy Matching: Compares detected plates with database. \\n- PostgreSQL Database: Stores valid plates and access permissions. \\n3.4 Integration Points \\nThis module integrates with the pipeline orchestrator to process vehicle footage and update access \\nlogs. \\n3.5 Implementation Details'), Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 7, 'source_file': 'Civil-Supplies-Documentation-V1.pdf', 'file_type': 'pdf'}, page_content='logs. \\n3.5 Implementation Details \\nProcesses every nth frame (fps/3), aggregates OCR results, and locks final matches once validated \\nwith the database. \\n \\n3.6 YOLO model metric graphs:'), Document(metadata={'producer': '', 'creator': 'Microsoft Word', 'creationdate': '2025-09-18T20:40:19-07:00', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'total_pages': 9, 'format': 'PDF 1.7', 'title': '', 'author': 'python-docx', 'subject': '', 'keywords': '', 'moddate': '2025-09-18T20:40:19-07:00', 'trapped': '', 'modDate': \"D:20250918204019-07'00'\", 'creationDate': \"D:20250918204019-07'00'\", 'page': 8, 'source_file': 'Civil-Supplies-Documentation-V1.pdf', 'file_type': 'pdf'}, page_content='3.6.1. mAP over Training Epochs \\n \\n   3.6.2. Training vs Validation Loss')]\n"
     ]
    }
   ],
   "source": [
    "def split_document(documents,chunk_size=1000,chunk_overlap=100):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=chunk_size,\n",
    "                                                 chunk_overlap=chunk_overlap, \n",
    "                                                 length_function=len,\n",
    "                                                 separators=[\"\\n\\n\", \"\\n\", \" \", \"\"])\n",
    "    split_docs=text_splitter.split_documents(documents)\n",
    "    print(f\"splitted {len(all_pdf_documents)} into {len(split_docs)} chunks\")\n",
    "    print(split_docs)\n",
    "    return split_docs\n",
    "chunks=split_document(all_pdf_documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb44d45",
   "metadata": {},
   "source": [
    "Embeddings generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "422f5fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sentence_transformers import SentenceTransformer \n",
    "import chromadb \n",
    "from chromadb.config import Settings \n",
    "import uuid \n",
    "from typing import List, Dict, Any, Tuple \n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d35f152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n",
      "Model loaded successfully. Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "     \"\"\"Handles document embedding generation using SentenceTransformer\"\"\" \n",
    "     def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "         #Initialize the embedding manager Args: model name: HuggingFace model name for sentence embeddings \n",
    "         self.model_name= model_name \n",
    "         self.model=None \n",
    "         self._load_model()\n",
    "     def _load_model(self): \n",
    "        \"\"\"Load the SentenceTransformer model\"\"\" \n",
    "        try: \n",
    "            print(f\"Loading embedding model: {self.model_name}\") \n",
    "            self.model=SentenceTransformer(self.model_name) \n",
    "            print(f\"Model loaded successfully. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\") \n",
    "        except Exception as e: \n",
    "            print(f\"Error loading model {self.model_name}: {e}\") \n",
    "     def generate_embeddings(self,texts:List[str]) :\n",
    "         if not self.model:\n",
    "             print(\"model not loaded\")\n",
    "         embeddings=self.model.encode(texts,show_progress_bar=True)\n",
    "         print(f\"length of embeddings are {len(embeddings)}\")\n",
    "         return embeddings\n",
    "embedding_manager=EmbeddingManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a008ac",
   "metadata": {},
   "source": [
    "Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8126049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collection is created with name: pdf_documents\n"
     ]
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    def __init__(self,collection_name:str=\"pdf_documents\",persistent_directory:str=\"vector_store\"):\n",
    "        self.collection_name=collection_name\n",
    "        self.persistent_directory=persistent_directory\n",
    "        self.collection=None\n",
    "        self.client=None\n",
    "        self._initialize_store()\n",
    "    def _initialize_store(self):\n",
    "        os.makedirs(self.persistent_directory,exist_ok=True)\n",
    "        self.client=chromadb.PersistentClient(path=self.persistent_directory)\n",
    "        self.collection=self.client.get_or_create_collection(\n",
    "            name=self.collection_name,\n",
    "            metadata={\"description\":\"Am creating the collection using ChromaDB\"}\n",
    "            \n",
    "        )\n",
    "        print(f\"collection is created with name: {self.collection_name}\")\n",
    "        # print(f\"number of documents in {self.collection_name}\")\n",
    "    def add_documents(self,documents:List[Any],embeddings:np.ndarray):\n",
    "        if len(documents)!=len(embeddings):\n",
    "            return None\n",
    "        ids=[]\n",
    "        metadatas=[]\n",
    "        documents_text=[]\n",
    "        embeddings_list=[]\n",
    "        for i,(doc,embedding) in enumerate(zip(documents,embeddings)):\n",
    "            #Generate unique ID \n",
    "            doc_id=f\"doc_(uuid.uuid4().hex[:8])_{i}\" \n",
    "            ids.append(doc_id) \n",
    "            # Prepare metadata \n",
    "            metadata=dict(doc.metadata) \n",
    "            metadata['doc_index'] = i \n",
    "            metadata['content_length'] = len(doc.page_content) \n",
    "            metadatas.append(metadata) \n",
    "            #Document content \n",
    "            documents_text.append(doc.page_content) \n",
    "            # Embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "            try:\n",
    "                self.collection.add(\n",
    "                    ids=ids,\n",
    "                    embeddings=embeddings_list,\n",
    "                    metadatas=metadatas,\n",
    "                    documents=documents_text\n",
    "                )\n",
    "                print(f\"successfully added the document to the {self.collection_name}\")\n",
    "                print(f\"Total documents in the colllection: {self.collection.count()}\")\n",
    "            except:\n",
    "                print(\"Error adding documents to the store\")\n",
    "vector_store=VectorStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f6fb31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text chunks are;  ['Civil Supplies Project Documentation \\nThe Civil Supplies Project automates the monitoring and management of warehouse activities using \\nthree integrated systems: \\n- Facial Recognition System for identifying individuals. \\n- Gunny Bags Counting System for tracking loading and unloading activities. \\n- Number Plate Recognition System for vehicle access control. \\nThese systems work together through a unified pipeline that processes live video feeds, enhancing \\noperational efficiency, security. \\n \\nPrerequisites & Configuration \\nBefore running the Civil Supplies Warehouse pipeline, ensure these secrets are configured in GitHub: \\n Azure Configuration \\n• \\nAZURE_TENANT_ID – Tenant ID for Azure authentication. \\n• \\nAZURE_CLIENT_ID – Client ID of the registered Azure application. \\n• \\nAZURE_CLIENT_SECRET – Client secret for the registered Azure application. \\n• \\nAZURE_STORAGE_ACCOUNT_NAME – Storage account name. \\n• \\nAZURE_CONTAINER_NAME – Container name for storing CCTV video chunks.', '• \\nAZURE_CONTAINER_NAME – Container name for storing CCTV video chunks. \\nPostgreSQL Database \\n• \\nPG_HOST – Host IP/hostname of the database server. \\n• \\nPG_PORT – Database port. \\n• \\nPG_USER – Database user. \\n• \\nPG_PASSWORD – Database user password. \\n• \\nPG_DATABASE – Database name. \\n \\nPipeline Breakdown: \\n1. Video Ingestion and Storage \\n• \\nComponent: AWS Lambda (WarehouseAzure-S3-Transfer-Video-Function)', '• \\nProcess: Continuously monitors the live CCTV feed (RTSP/RTMP). \\n• \\nAction: Segments the feed into short video clips (.ts/.mp4) and uploads them to Azure Blob \\nStorage (e.g., spectradevdev). \\n \\n2. Job Triggering \\n• \\nComponent: AWS Lambda (API Trigger) \\n• \\nProcess: Listens for new blob upload events in Azure. \\n• \\nAction: Sends an HTTP POST request (/api/process) to the FastAPI Main Service, including \\nthe blob URL and task metadata. \\n \\n3. Frame Preparation \\n• \\nComponent: FastAPI Main Service \\n• \\nSubmodules: \\no \\nazure_downloader.py → Downloads the video clip from Azure Blob. \\no \\nframe_extractor.py → Converts the video into sequential frames for analysis. \\n \\n4. Orchestration and Model Inference \\n• \\nComponent: Task Orchestrator (videoprocessor.py) \\n• \\nProcess: Reads task type (Gunny bag, Face, NumberPlate) from the trigger payload. \\n• \\nAction: Dispatches frames to the relevant services: \\no \\nGunnybag Counting Service \\no \\nFacial Recognition Service \\no \\nLicense Plate Recognition Service \\n•', 'Gunnybag Counting Service \\no \\nFacial Recognition Service \\no \\nLicense Plate Recognition Service \\n• \\nOutput: Each service processes frames and produces structured results. \\n \\n5. Persistence and Response \\n• \\nComponent: DB Handler + FastAPI Response', '• \\nProcess: \\no \\nDB Handler writes structured results into corresponding database tables (gunny \\nbags, faces, numberplates). \\no \\nFastAPI endpoint sends a JSON response back to the client confirming job \\ncompletion. \\nSystem Architecture:', 'Services  \\n1. Facial Recognition System \\nThe Facial Recognition System identifies individuals captured in warehouse CCTV feeds. It aims to \\nautomate identity verification, improve security, and maintain accurate logs. \\n1.1 Workflow \\nFrame Input  \\n      ↓ \\nPerson Detection (YOLOv8l) \\n      ↓ \\nTracking (BoT-SORT) \\n      ↓ \\nFace Cropping \\n      ↓ \\nFace Recognition (Buffalo_L) \\n      ↓ \\nResult Aggregation \\n      ↓ \\nFinal Output \\n \\n1.2 Models Used \\n• \\nYOLOv8l \\no \\nTask: Person detection in frames. \\no \\nmAP (mean Average Precision): 52.9. \\n• \\nBuffalo_L (InsightFace) \\no \\nTask: Face embedding extraction for recognition. \\no \\nAccuracy: 93.16% on standard benchmarks.', \"1.3 Key Technical Components \\n- YOLOv8l: Detects persons in video frames. \\n- BoT-SORT Tracker: Maintains consistent IDs across frames. \\n- Buffalo_L Model: Extracts embeddings for recognition. \\n- FAISS: Performs fast similarity searches on embeddings. \\n- Database (face_database.pkl): Stores known embeddings. \\n- Asyncio → Offloads CPU-heavy tasks like embedding extraction and FAISS search to \\n1.4 Integration Points \\nThis module integrates with the pipeline's frame extractor and orchestrator to process faces from \\nvideo clips stored in the cloud. \\n1.5 Implementation Details \\nThe pipeline resets trackers per clip, processes every 5th frame for recognition, and aggregates \\nresults to produce consistent identity outputs. \\n2. Gunny Bags Counting System \\nThe Gunny Bags Counting System tracks and counts gunny bags being loaded or unloaded across a \\ndefined line. Its goal is to automate inventory updates and reduce manual counting errors. \\n2.1 Workflow \\n \\nInput Video \\n      ↓\", '2.1 Workflow \\n \\nInput Video \\n      ↓ \\nYOLO Detection (Gunny Bags) \\n      ↓ \\nNon-Max Suppression \\n      ↓ \\nTracking (Kalman Filter + Hungarian Algorithm) \\n      ↓ \\nCrossing Detection \\n      ↓ \\nCount Updates \\n      ↓ \\nOutput Statistics', '2.2 Models Used  \\n• \\nYOLO (Ultralytics)  \\no \\nTask: Detect gunny bags in each video frame.  \\no \\nConfidence threshold: 0.35. \\n• \\nKalman Filter (OpenCV)  \\no \\nTask: Smooth object trajectories and predict positions when detections are \\nmissing.  \\n• \\nHungarian Algorithm (scipy.optimize.linear_sum_assignment)  \\no \\nTask: Assign detections to existing tracks with minimum cost based on IoU and \\ndistance. \\n2.3 Key Technical Components \\n- YOLO (Ultralytics): Detects gunny bags. \\n- Kalman Filter: Smooths trajectories and predicts missing detections. \\n- Hungarian Algorithm: Matches detections to tracks. \\n- Crossing Detection Logic: Determines loading/unloading events. \\n2.4 Integration Points \\nThis module integrates with the pipeline to process warehouse footage and provide real-time \\nloading/unloading statistics. \\n2.5 Implementation Details \\nTracks have defined states (tentative → confirmed). Events are detected based on line crossing, with \\nlogs produced at regular frame intervals.', 'logs produced at regular frame intervals. \\n2.6 Model Related Graphs:', '3. Number Plate Recognition System \\nThe Number Plate Recognition System identifies and verifies vehicle license plates entering or exiting \\nthe warehouse. It ensures secure access control by matching plates against an authorized database. \\n3.1 Workflow \\n \\nVideo Input \\n      ↓ \\nYOLO Detection (License Plates) \\n      ↓ \\nTracking (BoT-SORT) \\n      ↓ \\nOCR (PaddleOCR) \\n      ↓ \\nCleaning & Validation \\n      ↓ \\nFuzzy Matching with Database', '↓ \\nResult Aggregation \\n      ↓ \\nFinal Output \\n3.2 Models Used \\n• \\nYOLO (License Plate Detection):  \\no \\nTask: Detect license plates in frames.   \\no \\nmAP@0.5: 0.9759 \\no \\nAP@0.5:0.95: 0.8997 \\no \\nPrecision: 0.9849 \\no \\nRecall: 0.9457 \\n• \\nPaddleOCR:  \\no \\nTask: Extract alphanumeric text from cropped license plate regions.   \\no \\nCharacter Matching Accuracy: ~96% – 98% \\no \\nBLEU Score: ~0.93% – 0.96% \\no \\nBoT-SORT Tracker: Maintain consistent tracking IDs across frames for each \\nvehicle/plate.     \\n \\n3.3 Key Technical Components \\n- YOLO: Detects license plates. \\n- PaddleOCR: Extracts alphanumeric text. \\n- BoT-SORT Tracker: Maintains persistent IDs. \\n- Regex Validators: Validate plate formats. \\n- Fuzzy Matching: Compares detected plates with database. \\n- PostgreSQL Database: Stores valid plates and access permissions. \\n3.4 Integration Points \\nThis module integrates with the pipeline orchestrator to process vehicle footage and update access \\nlogs. \\n3.5 Implementation Details', 'logs. \\n3.5 Implementation Details \\nProcesses every nth frame (fps/3), aggregates OCR results, and locks final matches once validated \\nwith the database. \\n \\n3.6 YOLO model metric graphs:', '3.6.1. mAP over Training Epochs \\n \\n   3.6.2. Training vs Validation Loss']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts=[doc.page_content for doc in chunks]\n",
    "print(\"Text chunks are; \",texts)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a74de7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of embeddings are 14\n",
      "[[-0.04572309  0.02351205 -0.07256225 ... -0.00854249 -0.0196133\n",
      "  -0.10350119]\n",
      " [ 0.03053385 -0.03236363 -0.10852879 ...  0.01276315  0.04849378\n",
      "  -0.05026677]\n",
      " [-0.01106906 -0.04497927 -0.09534009 ...  0.06563845 -0.00387122\n",
      "  -0.05113655]\n",
      " ...\n",
      " [-0.07153378  0.02568216 -0.04570009 ...  0.00066344  0.01521763\n",
      "  -0.07928558]\n",
      " [-0.04274938 -0.0575447  -0.03892815 ... -0.06579547  0.03259268\n",
      "  -0.03001297]\n",
      " [-0.01270368  0.02244613  0.06478529 ... -0.04106241 -0.02070728\n",
      "  -0.0289937 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings=embedding_manager.generate_embeddings(texts)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79a270b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully added the document to the pdf_documents\n",
      "Total documents in the colllection: 14\n",
      "successfully added the document to the pdf_documents\n",
      "Total documents in the colllection: 14\n",
      "successfully added the document to the pdf_documents\n",
      "Total documents in the colllection: 14\n",
      "successfully added the document to the pdf_documents\n",
      "Total documents in the colllection: 14\n",
      "successfully added the document to the pdf_documents\n",
      "Total documents in the colllection: 14\n",
      "successfully added the document to the pdf_documents\n",
      "Total documents in the colllection: 14\n",
      "successfully added the document to the pdf_documents\n",
      "Total documents in the colllection: 14\n",
      "successfully added the document to the pdf_documents\n",
      "Total documents in the colllection: 14\n",
      "successfully added the document to the pdf_documents\n",
      "Total documents in the colllection: 14\n",
      "successfully added the document to the pdf_documents\n",
      "Total documents in the colllection: 14\n",
      "successfully added the document to the pdf_documents\n",
      "Total documents in the colllection: 14\n",
      "successfully added the document to the pdf_documents\n",
      "Total documents in the colllection: 14\n",
      "successfully added the document to the pdf_documents\n",
      "Total documents in the colllection: 14\n",
      "successfully added the document to the pdf_documents\n",
      "Total documents in the colllection: 14\n"
     ]
    }
   ],
   "source": [
    "vector_store.add_documents(chunks,embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804b62ea",
   "metadata": {},
   "source": [
    "Creating RAG Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da2efbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for the query: about civil supplies project\n",
      "default top_k is:5 and score_threshold is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 37.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of embeddings are 1\n",
      "{'ids': [['doc_(uuid.uuid4().hex[:8])_2', 'doc_(uuid.uuid4().hex[:8])_6', 'doc_(uuid.uuid4().hex[:8])_5', 'doc_(uuid.uuid4().hex[:8])_4', 'doc_(uuid.uuid4().hex[:8])_8']], 'embeddings': None, 'documents': [['Designed and deployed modules for a government surveillance product, including hands-on evaluations\\nof CCTV camera placements in government warehouses and on-site demonstrations in government\\noffices.\\nCollaborated with stakeholders to ensure compliance with operational and security requirements,\\nproviding actionable insights for real-world government environments.\\nSRAVAN POTNURU\\nP R O J E C T S\\nProject: ParaBot (AI Chat + File Summarizer) | FastAPI, React, OCR, Gemini | GitHub  \\nImplemented an AI assistant that processes text, images, PDFs, and website content with summarization and Q&A\\ncapabilities.\\nProject: Stress Prediction Based on Sleeping Patterns | Python, ML, Streamlit | GitHub\\nDeveloped a machine learning model that predicts stress levels using sleep data and provides wellness suggestions.\\nProject: ScreenSaga (OTT Platform) | React JS, Spring RestAP, MySQL | GitHub (frontend) | GitHub (Backend)', 'side drawer for filters, real-time map updates, and fast, responsive UI for desktop and mobile users.\\nD E C L A R A T I O N\\n I, POTNURU SRAVANKUMAR hereby declare that the above mentioned information is corrected up to my knowledge and belief; I\\nbear the responsibility for the correctness of the above mentioned particulars.\\nPlace: Nuzvid\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\np.sravan kumar', 'Web Technologies and Libraries: HTML, CSS,\\nBootstrap, React JS\\nProgramming:  Java, Python\\nQuery Languages/Database: MySQL\\nFrameworks: Collections, Hibernate, Spring ,\\nStreamlit (Python)\\nMachine Learning & AI: Machine Learning,   \\nModels: YOLO, Buffalo Insightface\\nTesting: Postman\\nAPI: Fast API, Spring REST API\\nCloud: AWS\\nData Visualization: Power BI\\nTools: Netlify, Vercel, VS Code, Jupyter\\nNotebook, Eclipse, PowerPoint\\nSource Code Management: GIT\\nPre- University Course (PUC) - Intermediate\\nRGUKT IIIT  Nuzvid       \\n2019 - 2021\\nCGPA: 9.62\\nSecondary School - SSC\\nGovernment High School, Srikakulam   \\n2018 - 2019\\nCGPA: 10\\nProject: Company Vault - Filter, Explore, and Locate Companies | React, Material-UI, JSON Server, Vercel | GitHub\\nDeveloped a responsive web application to discover companies with advanced filtering (industry, location, rating,\\nrevenue, employee count), interactive maps with directions, and modals showing company reviews. Implemented a', \"C E R T I F I C A T I O N\\nSuccessful completion certificate on Java Development Internship.\\nCertification on 7-Days Bootcamp on Basic Web-Dev With Bootstrap.\\nCertification on completion of JavaScript and React JS bootcamp.\\nCertification on completion on Resume, Networking and Interview Skills.\\nC O - C U R R I C U L A R\\nAchieved NCC 'B' Certificate and 'C' Certificate.\\nCertification on completion on Resume, Networking and Interview Skills.\\nCertificate of Merit for All India Essay Writing Event 2018.\\nCertificate of Participation and Certificate of Appreciation for National Level Techno Management Fest \\nCertificate of Participation for All India Inter-University Yoga Championship (2019-2020)\\nC O N T A C T\\n+91 9391872342\\nsravanpotnuru24@gmail.com\\nLinkedIn\\nPortfolio UI\\nRGUKT IIIT  Nuzvid            \\nB.Tech - Computer Science Engineering (CSE)\\n2021 - 2025\\nE D U C A T I O N\\nCGPA: 9.0\\nT E C H  S T A C K\\nWeb Technologies and Libraries: HTML, CSS,\\nBootstrap, React JS\\nProgramming:  Java, Python\", '2.2 Models Used  \\n• \\nYOLO (Ultralytics)  \\no \\nTask: Detect gunny bags in each video frame.  \\no \\nConfidence threshold: 0.35. \\n• \\nKalman Filter (OpenCV)  \\no \\nTask: Smooth object trajectories and predict positions when detections are \\nmissing.  \\n• \\nHungarian Algorithm (scipy.optimize.linear_sum_assignment)  \\no \\nTask: Assign detections to existing tracks with minimum cost based on IoU and \\ndistance. \\n2.3 Key Technical Components \\n- YOLO (Ultralytics): Detects gunny bags. \\n- Kalman Filter: Smooths trajectories and predicts missing detections. \\n- Hungarian Algorithm: Matches detections to tracks. \\n- Crossing Detection Logic: Determines loading/unloading events. \\n2.4 Integration Points \\nThis module integrates with the pipeline to process warehouse footage and provide real-time \\nloading/unloading statistics. \\n2.5 Implementation Details \\nTracks have defined states (tentative → confirmed). Events are detected based on line crossing, with \\nlogs produced at regular frame intervals.']], 'uris': None, 'included': ['metadatas', 'documents', 'distances'], 'data': None, 'metadatas': [[{'source': 'data\\\\pdf_files\\\\sravan_potnuru.pdf', 'trapped': '', 'source_file': 'sravan_potnuru.pdf', 'content_length': 916, 'producer': 'Canva', 'moddate': '2025-10-23T08:55:45+00:00', 'modDate': \"D:20251023085545+00'00'\", 'total_pages': 2, 'creationDate': \"D:20251023085546+00'00'\", 'creationdate': '2025-10-23T08:55:46+00:00', 'title': 'Copy of Sravan potnuru', 'keywords': 'DAG2irj_3ks,BAErSMjiGi8,0', 'subject': '', 'format': 'PDF 1.4', 'author': 'Sravan Potnuru', 'page': 0, 'creator': 'Canva', 'file_type': 'pdf', 'doc_index': 2, 'file_path': 'data\\\\pdf_files\\\\sravan_potnuru.pdf'}, {'moddate': '2025-10-23T08:55:45+00:00', 'total_pages': 2, 'page': 1, 'source_file': 'sravan_potnuru.pdf', 'creationdate': '2025-10-23T08:55:46+00:00', 'file_path': 'data\\\\pdf_files\\\\sravan_potnuru.pdf', 'title': 'Copy of Sravan potnuru', 'keywords': 'DAG2irj_3ks,BAErSMjiGi8,0', 'author': 'Sravan Potnuru', 'source': 'data\\\\pdf_files\\\\sravan_potnuru.pdf', 'subject': '', 'creationDate': \"D:20251023085546+00'00'\", 'modDate': \"D:20251023085545+00'00'\", 'content_length': 366, 'creator': 'Canva', 'file_type': 'pdf', 'doc_index': 6, 'format': 'PDF 1.4', 'trapped': '', 'producer': 'Canva'}, {'doc_index': 5, 'source_file': 'sravan_potnuru.pdf', 'page': 1, 'source': 'data\\\\pdf_files\\\\sravan_potnuru.pdf', 'modDate': \"D:20251023085545+00'00'\", 'creationdate': '2025-10-23T08:55:46+00:00', 'author': 'Sravan Potnuru', 'file_type': 'pdf', 'producer': 'Canva', 'subject': '', 'content_length': 963, 'trapped': '', 'keywords': 'DAG2irj_3ks,BAErSMjiGi8,0', 'total_pages': 2, 'format': 'PDF 1.4', 'creationDate': \"D:20251023085546+00'00'\", 'moddate': '2025-10-23T08:55:45+00:00', 'creator': 'Canva', 'file_path': 'data\\\\pdf_files\\\\sravan_potnuru.pdf', 'title': 'Copy of Sravan potnuru'}, {'doc_index': 4, 'subject': '', 'file_type': 'pdf', 'modDate': \"D:20251023085545+00'00'\", 'page': 1, 'creationDate': \"D:20251023085546+00'00'\", 'file_path': 'data\\\\pdf_files\\\\sravan_potnuru.pdf', 'producer': 'Canva', 'moddate': '2025-10-23T08:55:45+00:00', 'title': 'Copy of Sravan potnuru', 'creator': 'Canva', 'source_file': 'sravan_potnuru.pdf', 'format': 'PDF 1.4', 'author': 'Sravan Potnuru', 'creationdate': '2025-10-23T08:55:46+00:00', 'source': 'data\\\\pdf_files\\\\sravan_potnuru.pdf', 'trapped': '', 'total_pages': 2, 'content_length': 998, 'keywords': 'DAG2irj_3ks,BAErSMjiGi8,0'}, {'total_pages': 9, 'producer': '', 'moddate': '2025-09-18T20:40:19-07:00', 'file_path': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'page': 5, 'source_file': 'Civil-Supplies-Documentation-V1.pdf', 'creationdate': '2025-09-18T20:40:19-07:00', 'modDate': \"D:20250918204019-07'00'\", 'doc_index': 8, 'title': '', 'creator': 'Microsoft Word', 'content_length': 983, 'subject': '', 'source': 'data\\\\pdf_files\\\\Civil-Supplies-Documentation-V1.pdf', 'author': 'python-docx', 'keywords': '', 'file_type': 'pdf', 'trapped': '', 'format': 'PDF 1.7', 'creationDate': \"D:20250918204019-07'00'\"}]], 'distances': [[1.5739951133728027, 1.583634376525879, 1.5968458652496338, 1.618736982345581, 1.7094736099243164]]}\n",
      "Retrieving results for the query:about civil supplies project\n",
      "Retrieved 5 after filtering\n",
      "------------------------------------------------------------------\n",
      "Result: 1: Designed and deployed modules for a government surveillance product, including hands-on evaluations\n",
      "of CCTV camera placements in government warehouses and on-site demonstrations in government\n",
      "offices.\n",
      "Collaborated with stakeholders to ensure compliance with operational and security requirements,\n",
      "providing actionable insights for real-world government environments.\n",
      "SRAVAN POTNURU\n",
      "P R O J E C T S\n",
      "Project: ParaBot (AI Chat + File Summarizer) | FastAPI, React, OCR, Gemini | GitHub  \n",
      "Implemented an AI assistant that processes text, images, PDFs, and website content with summarization and Q&A\n",
      "capabilities.\n",
      "Project: Stress Prediction Based on Sleeping Patterns | Python, ML, Streamlit | GitHub\n",
      "Developed a machine learning model that predicts stress levels using sleep data and provides wellness suggestions.\n",
      "Project: ScreenSaga (OTT Platform) | React JS, Spring RestAP, MySQL | GitHub (frontend) | GitHub (Backend)\n",
      "------------------------------------------------------------------\n",
      "Result: 2: side drawer for filters, real-time map updates, and fast, responsive UI for desktop and mobile users.\n",
      "D E C L A R A T I O N\n",
      " I, POTNURU SRAVANKUMAR hereby declare that the above mentioned information is corrected up to my knowledge and belief; I\n",
      "bear the responsibility for the correctness of the above mentioned particulars.\n",
      "Place: Nuzvid            \n",
      "p.sravan kumar\n",
      "------------------------------------------------------------------\n",
      "Result: 3: Web Technologies and Libraries: HTML, CSS,\n",
      "Bootstrap, React JS\n",
      "Programming:  Java, Python\n",
      "Query Languages/Database: MySQL\n",
      "Frameworks: Collections, Hibernate, Spring ,\n",
      "Streamlit (Python)\n",
      "Machine Learning & AI: Machine Learning,   \n",
      "Models: YOLO, Buffalo Insightface\n",
      "Testing: Postman\n",
      "API: Fast API, Spring REST API\n",
      "Cloud: AWS\n",
      "Data Visualization: Power BI\n",
      "Tools: Netlify, Vercel, VS Code, Jupyter\n",
      "Notebook, Eclipse, PowerPoint\n",
      "Source Code Management: GIT\n",
      "Pre- University Course (PUC) - Intermediate\n",
      "RGUKT IIIT  Nuzvid       \n",
      "2019 - 2021\n",
      "CGPA: 9.62\n",
      "Secondary School - SSC\n",
      "Government High School, Srikakulam   \n",
      "2018 - 2019\n",
      "CGPA: 10\n",
      "Project: Company Vault - Filter, Explore, and Locate Companies | React, Material-UI, JSON Server, Vercel | GitHub\n",
      "Developed a responsive web application to discover companies with advanced filtering (industry, location, rating,\n",
      "revenue, employee count), interactive maps with directions, and modals showing company reviews. Implemented a\n",
      "------------------------------------------------------------------\n",
      "Result: 4: C E R T I F I C A T I O N\n",
      "Successful completion certificate on Java Development Internship.\n",
      "Certification on 7-Days Bootcamp on Basic Web-Dev With Bootstrap.\n",
      "Certification on completion of JavaScript and React JS bootcamp.\n",
      "Certification on completion on Resume, Networking and Interview Skills.\n",
      "C O - C U R R I C U L A R\n",
      "Achieved NCC 'B' Certificate and 'C' Certificate.\n",
      "Certification on completion on Resume, Networking and Interview Skills.\n",
      "Certificate of Merit for All India Essay Writing Event 2018.\n",
      "Certificate of Participation and Certificate of Appreciation for National Level Techno Management Fest \n",
      "Certificate of Participation for All India Inter-University Yoga Championship (2019-2020)\n",
      "C O N T A C T\n",
      "+91 9391872342\n",
      "sravanpotnuru24@gmail.com\n",
      "LinkedIn\n",
      "Portfolio UI\n",
      "RGUKT IIIT  Nuzvid            \n",
      "B.Tech - Computer Science Engineering (CSE)\n",
      "2021 - 2025\n",
      "E D U C A T I O N\n",
      "CGPA: 9.0\n",
      "T E C H  S T A C K\n",
      "Web Technologies and Libraries: HTML, CSS,\n",
      "Bootstrap, React JS\n",
      "Programming:  Java, Python\n",
      "------------------------------------------------------------------\n",
      "Result: 5: 2.2 Models Used  \n",
      "• \n",
      "YOLO (Ultralytics)  \n",
      "o \n",
      "Task: Detect gunny bags in each video frame.  \n",
      "o \n",
      "Confidence threshold: 0.35. \n",
      "• \n",
      "Kalman Filter (OpenCV)  \n",
      "o \n",
      "Task: Smooth object trajectories and predict positions when detections are \n",
      "missing.  \n",
      "• \n",
      "Hungarian Algorithm (scipy.optimize.linear_sum_assignment)  \n",
      "o \n",
      "Task: Assign detections to existing tracks with minimum cost based on IoU and \n",
      "distance. \n",
      "2.3 Key Technical Components \n",
      "- YOLO (Ultralytics): Detects gunny bags. \n",
      "- Kalman Filter: Smooths trajectories and predicts missing detections. \n",
      "- Hungarian Algorithm: Matches detections to tracks. \n",
      "- Crossing Detection Logic: Determines loading/unloading events. \n",
      "2.4 Integration Points \n",
      "This module integrates with the pipeline to process warehouse footage and provide real-time \n",
      "loading/unloading statistics. \n",
      "2.5 Implementation Details \n",
      "Tracks have defined states (tentative → confirmed). Events are detected based on line crossing, with \n",
      "logs produced at regular frame intervals.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class RAGRetriever:\n",
    "    def __init__(self,vectorstore:VectorStore,embedding_manager:EmbeddingManager):\n",
    "        self.vectorstore=vectorstore\n",
    "        self.embedding_manager=embedding_manager\n",
    "    def retrieve(self,query:str,top_k:int=5,similarity_threshold:float=0.0):\n",
    "        print(f\"Retrieving documents for the query: {query}\")\n",
    "        print(f\"default top_k is:{top_k} and score_threshold is {similarity_threshold}\")\n",
    "        query_embedding=self.embedding_manager.generate_embeddings([query])[0]\n",
    "        # print(query_embedding)\n",
    "        # print([query_embedding.tolist()])\n",
    "        try:\n",
    "            results=self.vectorstore.collection.query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=top_k\n",
    "            )\n",
    "            print(results)\n",
    "            retrieved_docs=[]\n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                print(f\"Retrieving results for the query:{query}\")\n",
    "                documents=results['documents'][0]\n",
    "                metadatas=results['metadatas'][0]\n",
    "                distances=results['distances'][0]\n",
    "                ids=results['ids'][0]\n",
    "                for i,(document,metadata,id,distance) in enumerate(zip(documents,metadatas,ids,distances)):\n",
    "                    cosine=1-distance\n",
    "                    if cosine<=similarity_threshold:\n",
    "                        retrieved_docs.append(\n",
    "                            {\n",
    "                                \"id\":id,\n",
    "                                \"content\":document,\n",
    "                                \"metadata\":metadata,\n",
    "                                \"similarity_score\":cosine,\n",
    "                                \"distance\":distance,\n",
    "                                \"rank\":i+1\n",
    "                            }\n",
    "                        )\n",
    "                print(f\"Retrieved {len(retrieved_docs)} after filtering\")\n",
    "            else:\n",
    "                print(\"No records found\")\n",
    "            return retrieved_docs\n",
    "        except:\n",
    "            print(\"failed retrieving the results\")\n",
    "\n",
    "rag_retriever=RAGRetriever(vector_store,embedding_manager)\n",
    "retrieved_results=rag_retriever.retrieve(\"about civil supplies project\")\n",
    "# print(retrieved_results)\n",
    "for i,result in enumerate(retrieved_results):\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "    print(f\"Result: {i+1}: {result['content']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
